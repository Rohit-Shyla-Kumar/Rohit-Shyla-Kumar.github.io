
<!DOCTYPE html>
<html >
<head>
  <!-- Site made with Mobirise Website Builder v4.8.1, https://mobirise.com -->
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Mobirise v4.8.1, mobirise.com">
  <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
  <link rel="shortcut icon" href="assets/images/dsc-0365-128x192.png" type="image/x-icon">
  <meta name="description" content="Rohit Shyla Kumar's blog">
  <title>Blog-Adeventures-in1</title>
  <link rel="stylesheet" href="assets/web/assets/mobirise-icons/mobirise-icons.css">
  <link rel="stylesheet" href="assets/tether/tether.min.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap.min.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap-grid.min.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap-reboot.min.css">
  <link rel="stylesheet" href="assets/socicon/css/styles.css">
  <link rel="stylesheet" href="assets/animatecss/animate.min.css">
  <link rel="stylesheet" href="assets/dropdown/css/style.css">
  <link rel="stylesheet" href="assets/theme/css/style.css">
  <link rel="stylesheet" href="assets/mobirise/css/mbr-additional.css" type="text/css">



</head>
<body>
  <section class="menu cid-qY3WQZT1Wj" once="menu" id="menu2-i">



    <nav class="navbar navbar-expand beta-menu navbar-dropdown align-items-center navbar-toggleable-sm bg-color transparent">
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <div class="hamburger">
                <span></span>
                <span></span>
                <span></span>
                <span></span>
            </div>
        </button>
        <div class="menu-logo">
            <div class="navbar-brand">


            </div>
        </div>
        <div class="collapse navbar-collapse" id="navbarSupportedContent">
            <ul class="navbar-nav nav-dropdown nav-right navbar-nav-top-padding" data-app-modern-menu="true"><li class="nav-item">
                    <a class="nav-link link text-white display-4" href="index.html">
                        Home</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link link text-white display-4" href="index.html#content4-e">Experience</a>
                </li><li class="nav-item"><a class="nav-link link text-white display-4" href="blogadventures1.html">Blog</a></li></ul>

        </div>
    </nav>
</section>

<section class="engine"><a href="https://mobiri.se/j">website templates</a></section><section class="header1 cid-qY4fMMMjNL" id="header1-k">






    <div class="container">
        <div class="row justify-content-md-center">
                <h1 class="mbr-section-title align-center mbr-bold pb-3 mbr-fonts-style display-1">
                    Final Year Project Blog</h1>
        </div>
    </div>

</section>

<section class="mbr-section content4 cid-qY4gZECclL" id="content4-l">



    <div class="container">
        <div class="media-container-row">
            <div class="title col-12 col-md-8">
                <h2 class="align-center pb-3 mbr-fonts-style display-2">
                    Adventures in teaching bots how to kill people</h2> <br/>
                    <h3 class="mbr-section-subtitle align-center mbr-light mbr-fonts-style display-5">
                        Introduction</h3> <br/>
                    <p class="mbr-text align-left mb-0 mbr-fonts-style display-7">Welcome to my final year project blog, "Adventures in teaching bots how to kill people". This is where I document my thoughts and milestones while working on my final year project at the School of Creative Media, City University of Hong Kong. I update this page at least once a week in the form of chapters. My final goal for this project, titled "AI For General FPS" is a fairly bot capable of playing at the level of playing multiple different FPS games at the level of an average human player. </p> <br/>

            </div>
        </div>
    </div>
</section>

<section class="mbr-section article content3 cid-qYUMDBb4R7" id="content3-s">
    <br/>
  <div>
    <div class="container">
        <div class="media-container-row">
                <h3 class="mbr-section-subtitle align-center mbr-light mbr-fonts-style display-5">
                    Chapter 1</h3>
        </div>
        <br/>
    </div>
  </div>

    <div class="container">
        <div class="media-container-row">
            <div class="row col-12 col-md-8">
              <div class="mbr-section-text">
                <p class="mbr-text align-left mb-0 mbr-fonts-style display-7">If you follow developments in the AI field closely, you've probably already seen the Dota 2 match between Open AI bot and Dendi. In case you haven't, check it out <a href = https://www.youtube.com/watch?v=7U4-wvhgx0w style="color:blue">here.</a></p>
                <br><p class="mbr-text align-left mb-0 mbr-fonts-style display-7">Well, if I was going to pull off anything even close to this crazy, I'd need to find out what I'm up against first, so I started going through some of the literature on the topic, this is pretty much the very least you should be familiar with if you want to do something like this yourself.</p>
                <p class="mbr-text align-left mb-0 mbr-fonts-style display-7">
                  <div>
                  <br/><a style="color:blue" href="https://www.rand.org/content/dam/rand/pubs/papers/2008/P550.pdf">The Theory of Dynammic Programming by Richard Bellman </a> <br>
                  <a style="color:blue" href="https://pdfs.semanticscholar.org/968b/ab782e52faf0f7957ca0f38b9e9078454afe.pdf"> A Survey of Applications of Markov Decision Processes by D. J. White</a><br>
                  <a style="color:blue" href="https://link.springer.com/article/10.1007/BF00115009"> Learning to predict by the methods of temporal differences by Richard S. Sutton </a><br>
                  </div>
                </p>
                <br/>
                <p class="mbr-text align-left mb-0 mbr-fonts-style display-7">Now to the deep end, literally. Q-learning is fairly intutive, I was able to pick it up pretty fast and so should you. The basic concept is, we give our "agent" some reward for certain special states and ask it to evaluate a "policy" to maximize its score. Now I know this all sounds super techincal but it's really not. It's literally just the Markov equation evaluated with a max function from any standard library.
                  This kind of agent can solve a simple maze of a few hundred to few thousand grids easily. Quick sidenote, if you're wondering what Dynammic Programming has to do with any of this or why I linked you to that particular paper, it's because DP is father of a technique called memoization. When the agent is working it's way through the maze, you'll to memoize and update the Q values in a table the size of the maze.
                 </p><br/>
                 <p class="mbr-text align-left mb-0 mbr-fonts-style display-7">Deep Q-Learning is where the challenge really begins. For this you're gonna need to know what Artificial and Convolutional Neural Networks are. At this point I'd link a ton of resources to learn about them for your reference but I'm sure you don't need my help finding tutorials on the biggest buzzword of decade. <a href="https://www.youtube.com/watch?v=aircAruvnKk" style="color:blue"> Here's </a> just one quick 4 part video series that I thought was brilliant.</p>

              </div>
            </div>
        </div>
    </div>
</section>



<section class="mbr-section content4 cid-qY4gZECclL" id="content4-l">
  <div>
    <div class="container">
        <div class="media-container-row">
                <h3 class="mbr-section-subtitle align-center mbr-light mbr-fonts-style display-5">
                    Chapter 2</h3>
        </div>
        <br/>
    </div>
  </div>

    <div class="container">
        <div class="media-container-row">
            <div class="row col-12 col-md-8">
              <div class="mbr-section-text">
                <p class="mbr-text align-left mb-0 mbr-fonts-style display-7">We have some basic understanding of neural networks and reinforcement learning, now we need to sort out the non-machine learning stuff. First off, even if out bot knew how to play an FPS game, how would it? Making a physical robot to press buttons on a keyboard is obviously not a viable option. </p>
                <br><p class="mbr-text align-left mb-0 mbr-fonts-style display-7">What we need is an environment where my bot can play with direct access to the game’s controls. Thankfully, people have considered this problem before and built environments for some of the more popular game. OpenAI has a wonderful environment to train and test bots called OpenAI Gym. It covers a lot of Atari games and most importantly, for our purpose, Doom. Since the FPS genre started with Doom, I may as well start with Doom too. If you want to learn more about the OpenAI gym environment, please refer to the below research paper. </p>
                <p class="mbr-text align-left mb-0 mbr-fonts-style display-7">
                  <div>
                  <br/><a style="color:blue" href="https://pdfs.semanticscholar.org/2b10/281297ee001a9f3f4ea1aa9bea6b638c27df.pdf">About OpenAI Gym </a> <br>
                </p>
                <br/>
                <p class="mbr-text align-left mb-0 mbr-fonts-style display-7">There’s also been some research on bots that can play Quake 3, another game that absolutely defined the genre. Find out more <a href="https://arxiv.org/pdf/1807.01281.pdf" style="color:blue">here</a>. These environments are open source and thus the best place for me to start as compared to writing my own code to run on top of the game for my bot to access the controls and receive rewards.
                 </p><br/>

              </div>
            </div>
        </div>
    </div>


</section>

<section class="mbr-section article content3 cid-qYUMDBb4R7" id="content3-s">
  <br/>
  <div>
    <div class="container">
        <div class="media-container-row">
                <h3 class="mbr-section-subtitle align-center mbr-light mbr-fonts-style display-5">
                    Chapter 3</h3>
        </div>
        <br/>
    </div>
  </div>

    <div class="container">
        <div class="media-container-row">
            <div class="row col-12 col-md-8">
              <div class="mbr-section-text">
                <p class="mbr-text align-left mb-0 mbr-fonts-style display-7">Thanks to the environments, all I need is a program that can make decisions on which action to play given some video input. These actions are typically indexed by numbers, for example, 0 might be to press the W key and move forward and so on. Of course, analysing video feed is no simple task for a computer, in fact, until recently this component of the project alone was considered worthy of international awards. For this task, we must make use of a convolutional neural network to process the images (video feed is just images played at several frames per second). Since we’ll be working with multiple games, our architecture must be ready to accommodate multiple convolutional nets that perform image segmentation and recognition, one for each game to be precise. </p>
                <br><p class="mbr-text align-left mb-0 mbr-fonts-style display-7">We’ll also need an LSTM layer or some other recurrent architecture to accommodate time delayed rewards from the system. Now, if you’re wondering what that means, take a look at this paper on <a style="color:blue" href= "https://arxiv.org/pdf/1602.01783.pdf">Asynchronous Methods for Deep Reinforcement Learning by Volodymyr Mnih (2016) </a> </p>
                <br/>
                <p class="mbr-text align-left mb-0 mbr-fonts-style display-7">So, our plan of action is build an deep reinforcement learning system that receives as input the positions of various items of interest in the scene as a vector and outputs the Q values for each action. We then select an action either based on a softmax or an adaptive epsilon greedy strategy. We have a separate convolutional neural network for each game so it’s easier to tag items that look different in different games.
                 </p><br/>

              </div>
            </div>
        </div>
    </div>
</section>

<section class="mbr-section content4 cid-qY4gZECclL" id="content4-l">
  <div>
    <div class="container">
        <div class="media-container-row">
                <h3 class="mbr-section-subtitle align-center mbr-light mbr-fonts-style display-5">
                    Chapter 4</h3>
        </div>
        <br/>
    </div>
  </div>

    <div class="container">
        <div class="media-container-row">
            <div class="row col-12 col-md-8">
              <div class="mbr-section-text">
                <p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> When it comes to programming, there’s no better way to learn that by just trying things out so now that we have a fair idea of how to approach this task, we should start writing some code to model the outlined architecture. First, let’s install the necessary tools and libraries needed for the task, starting with an environment. Since I’m working with <a href= "https://www.python.org/" style= "color:blue">  Python </a>on the Windows platform, I’ll install <a href= "https://www.anaconda.com/download/" style= "color:blue"> Anaconda </a> for Windows and create a virtual environment to act as a container for the project. To create a virtual environment, use the command <strong> conda create -n venv pip python=3.6 </strong> where venv is the name of your environment.  </p>

                <br><p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> The libraries we need include numpy, scikitlearn, pandas, tensorflow (running on the GPU preferably), keras and opencv. To save you the trouble, I created a <a href= "/assets/requirements.txt" style= "color:blue"> requirements file </a>that you can download and install using the command <strong> pip install requirements.txt </strong></p>
                <p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> Numpy, scikitlearn and pandas are mostly for manipulating desirable datatypes like numpy arrays and dataframes while Tensorflow and Keras can be used to build the neural networks we require. OpenCV will help us process images efficiently.   </p><br/>

              </div>
            </div>
        </div>
    </div>


</section>

<section class="mbr-section article content3 cid-qYUMDBb4R7" id="content3-s">
  <br/>
  <div>
    <div class="container">
        <div class="media-container-row">
                <h3 class="mbr-section-subtitle align-center mbr-light mbr-fonts-style display-5">
                    Chapter 5</h3>
        </div>
        <br/>
    </div>
  </div>

    <div class="container">
        <div class="media-container-row">
            <div class="row col-12 col-md-8">
              <div class="mbr-section-text">
                <p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> Finally got assigned a computer at the CS lab in Mong Man Wai Building which is great because I can officially start development in a dedicated space. Of course, I’d have to reinstall all the software and libraries onto my new system. I decided to install Ubuntu, a popular Linux distribution on this PC so I could test my code on multiple platforms. Let’s just hope this doesn’t come back to bite me in back. So, I got to work flashing the OS, connecting to the new network and installing the dependencies on my new machine. Most of the process remains the same as detailed above, however, since I’m working on Linux, I can create virtual environments from the command line and Python comes preinstalled, so I didn’t have to install Anaconda. </p>
                <br><p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> For some further research, I also read the following papers and recommend strongly that you do the same. <br/>
                <a href = "https://arxiv.org/abs/1609.05521" style= "color:blue">Playing FPS Games With Deep Reinforcement Learning </a><br/>
                <a href = "https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf" style= "color:blue">Playing Atari With Deep Reinforcement Learning</a> </p>
                <br/>

              </div>
            </div>
        </div>
    </div>
</section>


<section class="mbr-section content4 cid-qY4gZECclL" id="content4-l">
  <div>
    <div class="container">
        <div class="media-container-row">
                <h3 class="mbr-section-subtitle align-center mbr-light mbr-fonts-style display-5">
                    Chapter 6</h3>
        </div>
        <br/>
    </div>
  </div>

    <div class="container">
        <div class="media-container-row">
            <div class="row col-12 col-md-8">
              <div class="mbr-section-text">
                <p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> Doing a comprehensive literature review in order to prepare properly for my interim presentation next week. I read the following research papers on the application of reinforcement learning in games with special emphasis the ones that used the ViZDoom engine which I plan on using. </p>
                <br><p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> <a href="https://openreview.net/pdf?id=Hk3mPK5gg" style="color:blue"> Training Agent For First-Person Shooter Game Wit Actor-Critic Curriculum Learning </a> <br/>
                  <a href="http://www.cs.cmu.edu/~dchaplot/papers/arnold_aaai17.pdf" style="color:blue"> Arnold: An Autonomous Agent to play FPS Games </a> <br/>
                  <a href="http://vladlen.info/papers/learning-to-act.pdf" style="color:blue"> Learning To Act By Predicting The Future </a> <br/>
                  <a href="https://arxiv.org/pdf/1606.02396.pdf" style="color:blue"> Deep Successor Reinforcement Learning </a> <br/>
                  <a href="https://arxiv.org/pdf/1807.01281.pdf" style="color:blue">  Human-level performance in first-person multiplayer games with population-based deep reinforcement learning </a> <br/>
                  <a href="https://link.springer.com/content/pdf/10.1007/11552413_40.pdf" style="color:blue"> Towards Using First-Person Shooter Computer Games as an Artificial Intelligence Testbed </a> <br/>
                  <a href="https://www.hindawi.com/journals/ijcgt/2008/432365/" style="color:blue"> A Hybrid Fuzzy ANN System for Agent Adaptation in a First Person Shooter </a> <br/>
                  <br/><p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> Yeah, I actually read all of them. Took me almost two days to completely wrap my head around some of the concepts detailed in each paper but it was definetly worth it for now I feel much more confident approaching this project. </p><br/>

              </div>
            </div>
        </div>
    </div>


</section>


<section class="mbr-section article content3 cid-qYUMDBb4R7" id="content3-s">
  <br/>
  <div>
    <div class="container">
        <div class="media-container-row">
                <h3 class="mbr-section-subtitle align-center mbr-light mbr-fonts-style display-5">
                    Chapter 7</h3>
        </div>
        <br/>
    </div>
  </div>

    <div class="container">
        <div class="media-container-row">
            <div class="row col-12 col-md-8">
              <div class="mbr-section-text">
                <p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> I started to tinker with the ViZDoom engine on Linux, just to get a feel of the environment. I started off simple with a script that just loaded the environment and played by selecting a random action at every step. Below is a screenshot of the clip. <br/> </p>
                <img src= "assets/images/script.PNG" width="800px" height="800px"> <br/>
                <br><p class="mbr-text align-left mb-0 mbr-fonts-style display-7">I also had my presentation due on Friday the 19th so I worked on writing my <a href= "assets/report.doc" style= "color:blue">report </a> and my presentation. Preparing the presentation and report helped me reflect on my progress thus far and bolstered my ability to plan my work for the weeks to come. <br/>
                <br/>

              </div>
            </div>
        </div>
    </div>
</section>


<section class="mbr-section content4 cid-qY4gZECclL" id="content4-l">
  <div>
    <div class="container">
        <div class="media-container-row">
                <h3 class="mbr-section-subtitle align-center mbr-light mbr-fonts-style display-5">
                    Chapter 8</h3>
        </div>
        <br/>
    </div>
  </div>

    <div class="container">
        <div class="media-container-row">
            <div class="row col-12 col-md-8">
              <div class="mbr-section-text">
                <p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> I installed PyTorch to test some reinforcement learning examples implemented with dynamic graphs and finally began training a simple RL model to play the basic scenario. The basic scenario is just a single room with a single enemy. The simple RL model is just a 4 layer neural network with 2 convolutional layers and 2 fully connected layers. I decided to write the first implementation of this network in Python3 with Tensorflow. It accepts a 30*45 grayscale image and can perform 3 actions, MOVE_LEFT, MOVE_RIGHT and FIRE. The model uses Q-Learning and implements it similarly to <a href= "https://storage.googleapis.com/deepmind-data/assets/papers/DeepMindNature14236Paper.pdf" style="color:blue" >Google DeepMind's DQN </a>(but not nearly as complicated). I assume that you know how Q-Learning works. If you don't I recommend watching <a href="https://www.youtube.com/watch?v=w33Lplx49_A" style="color:blue">AI lectures by Dan Klein and Pieter Abbeel (preferably taking the whole course).</a> </p>
                  <br/><p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> </p><br/>

              </div>
            </div>
        </div>
    </div>


</section>


<section class="mbr-section article content3 cid-qYUMDBb4R7" id="content3-s">
  <br/>
  <div>
    <div class="container">
        <div class="media-container-row">
                <h3 class="mbr-section-subtitle align-center mbr-light mbr-fonts-style display-5">
                    Chapter 9</h3>
        </div>
        <br/>
    </div>
  </div>

    <div class="container">
        <div class="media-container-row">
            <div class="row col-12 col-md-8">
              <div class="mbr-section-text">
                <p class="mbr-text align-left mb-0 mbr-fonts-style display-7">  After writing the scripts to train and test my model, as well as working out kinks with the display to record videos of the training process, I finally came up with a model that performed incredibly well on the basic scenario. Below are videos of the model playing the basic scenario of ZDoom before and after 20 epochs of training. <br/> </p>
                <video width="720" height="480" controls>
                <source src="assets/training-bad.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video>
                <br/> <br/>
                <br/>
                <video width="720" height="480" controls>
                <source src="assets/trained-good.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video>
                <p class="mbr-text align-left mb-0 mbr-fonts-style display-7">  As is fairly evident by the above videos, the performance of the model increased drastically from epoch 1 to epoch 20.  <br/> </p>
              </div>
            </div>
        </div>
    </div>
</section>

  <section class="mbr-section content4 cid-qY4gZECclL" id="content4-l">
  <div>
    <div class="container">
        <div class="media-container-row">
                <h3 class="mbr-section-subtitle align-center mbr-light mbr-fonts-style display-5">
                    Chapter 10</h3>
        </div>
        <br/>
    </div>
  </div>

    <div class="container">
        <div class="media-container-row">
            <div class="row col-12 col-md-8">
              <div class="mbr-section-text">
                <p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> After gaining some ground in Doom, I decided to shift my focus to Quake. My mind was set on making the same model work in a similar simple scenario of Quake. That would pretty much service as proof my initial idea to use the same model to play multiple shooters. In the current model, I just have 4 layers (as mentioned previously) the first two do the visual work being convolutional layers and the fully connected layers focus on the decision making with Q-Learning. I’m using the RMS loss function to introduce some non-linearities in the learning process. If the exact same architecture works on a simple Quake scenario, it would just be a matter of separating the visual cortex of each net for each game. To test it out, I had to download <a href="https://github.com/deepmind/lab" style="color:blue"> DeepMind Lab. </a> I learnt more about the Quake environment and DeepMind Lab by reading this <a href= "https://arxiv.org/pdf/1612.03801.pdf" style="color:blue">  paper </a> published by DeepMind. </a> </p>
                  <br/><p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> </p><br/>

              </div>
            </div>
        </div>
    </div>


</section>


<section class="mbr-section article content3 cid-qYUMDBb4R7" id="content3-s">
  <br/>
  <div>
    <div class="container">
        <div class="media-container-row">
                <h3 class="mbr-section-subtitle align-center mbr-light mbr-fonts-style display-5">
                    Chapter 11</h3>
        </div>
        <br/>
    </div>
  </div>

    <div class="container">
        <div class="media-container-row">
            <div class="row col-12 col-md-8">
              <div class="mbr-section-text">
                <p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> This week I added two convoluted layers (with max pooling) and one fully connected layer and let it have a go at the defend the centre scenario in Doom. After achieving less than ideal results, I increased the number of epochs and decreased the learning rate, giving the program more time to learn and adapt to the delta movements involved in this new situation. Below is the result of two days of training and tuning. It averaged 9 kills over it’s 10 best episodes. <br/><br/> </p>
                <video width="720" height="480" controls>
                <source src="assets/defend_the_center.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video>
                <br/>
             </div>
            </div>
        </div>
    </div>
</section>


  <section class="mbr-section content4 cid-qY4gZECclL" id="content4-l">
  <div>
    <div class="container">
        <div class="media-container-row">
                <h3 class="mbr-section-subtitle align-center mbr-light mbr-fonts-style display-5">
                    Chapter 12</h3>
        </div>
        <br/>
    </div>
  </div>

    <div class="container">
        <div class="media-container-row">
            <div class="row col-12 col-md-8">
              <div class="mbr-section-text">
                <p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> For fun, I played some defend the centre myself and had my friend play a few rounds too, just to get a better idea of what kind of progress I’d made (and to have some results to share during my presentation). I averaged 13 kills over 10 episodes, peaking at 16 kills in my best round and my friend averaged 9. Not looking too bad for the bot then, considering that I’ve been playing this and other games like it almost all my life. </p>
                  <br/><p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> I also fixed the issues I was having with Deepmind Lab but the basic scenario for the laser tag game in Quake Arena doesn’t seem to be as straightforward as the basic scenario of VizDoom. I also need to rewrite the final softmax to pick an action correctly in new environment. </p><br/>

              </div>
            </div>
        </div>
    </div>


</section>


<section class="mbr-section article content3 cid-qYUMDBb4R7" id="content3-s">
  <br/>
  <div>
    <div class="container">
        <div class="media-container-row">
                <h3 class="mbr-section-subtitle align-center mbr-light mbr-fonts-style display-5">
                    Chapter 13</h3>
        </div>
        <br/>
    </div>
  </div>

    <div class="container">
        <div class="media-container-row">
            <div class="row col-12 col-md-8">
              <div class="mbr-section-text">
                <p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> Week 13 was a busy week so I chose to focus my attention on the presentation and final report rather than the code. As any good software developer will tell you, never cram features in at the last minute. My final report can be found <a href = "assets/final_report.doc" style= "color:blue">here</a> and includes details on the methodology of my study and implementation of the programs so far.  <br/> </p>
                <br/>
             </div>
            </div>
        </div>
    </div>
</section>


<section class="mbr-section content4 cid-qY4gZECclL" id="content4-l">
<div>
  <div class="container">
      <div class="media-container-row">
              <h3 class="mbr-section-subtitle align-center mbr-light mbr-fonts-style display-5">
                  Chapter 14</h3>
      </div>
      <br/>
  </div>
</div>

  <div class="container">
      <div class="media-container-row">
          <div class="row col-12 col-md-8">
            <div class="mbr-section-text">
              <p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> DeepMind Lab is officially off the table now that I’ve spent my entire Christmas vacation tinkering with it to no end. The platform as currently hosted on GitHub simply has too many bugs for the Windows and Linux platforms. </p>
                <br/><p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> Of course, I have to replace one game with another so I did some more research on which game would be appropriate and after mulling over the choice between Wolfenstein 3D and Counter Strike 1.6, I’ve decided to go with Counter Strike 1.6 for now. Since we don’t have readymade platform built for training agents, we’re going to have to improvise. Next week, I’m going to try capturing my screen in full screen mode and look to process the video. </p><br/>

            </div>
          </div>
      </div>
  </div>


</section>


<section class="mbr-section article content3 cid-qYUMDBb4R7" id="content3-s">
  <br/>
  <div>
    <div class="container">
        <div class="media-container-row">
                <h3 class="mbr-section-subtitle align-center mbr-light mbr-fonts-style display-5">
                    Chapter 15</h3>
        </div>
        <br/>
    </div>
  </div>

    <div class="container">
        <div class="media-container-row">
            <div class="row col-12 col-md-8">
              <div class="mbr-section-text">
                <p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> Just as planned, I’ve written some scripts to capture my screen and to press different keys. You can find the script to capture your desktop screen in real time at about 20 fps  <a href = "assets/grabscreen.py" style= "color:blue">here</a> and a script to press the required keys to play CS1.6 <a href = "assets/keys.py" style= "color:blue">here.</a><br/> </p>
                <br/> <p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> The first logical step is to ensure this works with a simple script that presses random keys to make sure the actions are selected appropriately. After this, we should build up the solution reach the same level as the current Doom agent by first using a simple DQN and then a more complicated version.  </p><br/>
             </div>
            </div>
        </div>
    </div>
</section>

<section class="mbr-section content4 cid-qY4gZECclL" id="content4-l">
<div>
  <div class="container">
      <div class="media-container-row">
              <h3 class="mbr-section-subtitle align-center mbr-light mbr-fonts-style display-5">
                  Chapter 16</h3>
      </div>
      <br/>
  </div>
</div>

  <div class="container">
      <div class="media-container-row">
          <div class="row col-12 col-md-8">
            <div class="mbr-section-text">
              <p class="mbr-text align-left mb-0 mbr-fonts-style display-7">Below is a video of the CS1.6 agent before training. This week, I’m going to let the basic DQN train on some different maps, including aim_headshot which you can get <a href = "https://gamebanana.com/maps/8160" style= "color:blue">here</a>  and mini_dust which you can download <a href = "https://gamebanana.com/maps/196666" style= "color:blue">here.</a> </p>
                <br/><p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> Coming back to Doom for a while, it’s clear that this basic architecture we’ve implemented thus far is alright for the defend_the_center, defend_the_line and basic scenarios but it’s definitely not robust enough to play at the level I want it to, at the deathmatch level. So, we’re going to have to improve the architecture of the model itself. After reviewing some notes I took while writing chapter 6 (see above), I decided to go with a combination of the architectures described in “Training Agent For First-Person Shooter Game With Actor-Critic Curriculum Learning” and “Learning To Act By Predicting The Future” (again, see chapter 6).
                 </p><br/>

            </div>
          </div>
      </div>
  </div>


</section>


<section class="mbr-section article content3 cid-qYUMDBb4R7" id="content3-s">
  <br/>
  <div>
    <div class="container">
        <div class="media-container-row">
                <h3 class="mbr-section-subtitle align-center mbr-light mbr-fonts-style display-5">
                    Chapter 17</h3>
        </div>
        <br/>
    </div>
  </div>

    <div class="container">
        <div class="media-container-row">
            <div class="row col-12 col-md-8">
              <div class="mbr-section-text">
                <p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> This was quite a productive week. Below is a simple sketch of the architecture I went with for the system as a whole.  <br/>
                    <img src = "assets/net.jpg" width="640" height="480">
                <br/></p>
                <p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> Quickly summarizing, we have 3 separate networks, one convolutional for the input images, be it in Doom or CS1.6 (Doom for now) and two fully connected layers for the measurements and goals. This permits a system of dynamic goals which is especially important because it’s the basis of the logic we humans play with. For example, if you notice your health is low, your goal shifts from just getting kills to increasing your health by collecting health packs. Thus, our priorities shift over time and an agent that is only trying to optimize one goal will never succeed as we want it to in such a complex environment.   <br/></p>
                <br/> <p class="mbr-text align-left mb-0 mbr-fonts-style display-7">I’m writing all the code for the network with Tensorflow (despite the models shown in the papers being tested in PyTorch) because I feel confident with Tensorflow after working with it on a few other projects.  <br/></p>
             </div>
            </div>
        </div>
    </div>
</section>

<section class="mbr-section content4 cid-qY4gZECclL" id="content4-l">
<div>
  <div class="container">
      <div class="media-container-row">
              <h3 class="mbr-section-subtitle align-center mbr-light mbr-fonts-style display-5">
                  Chapter 18</h3>
      </div>
      <br/>
  </div>
</div>

  <div class="container">
      <div class="media-container-row">
          <div class="row col-12 col-md-8">
            <div class="mbr-section-text">
              <p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> I spent this week mostly preparing for and delivering my interim presentation. I think the presentation went okay but my supervisors definitely wanted to see the agent and try the interactive multiplayer I promised them instead of just videos of it. So that’s certainly going to be my focus for the coming weeks, to perfect the model and the interactive multiplayer.  </p>

            </div>
          </div>
      </div>
  </div>


</section>


<section class="mbr-section article content3 cid-qYUMDBb4R7" id="content3-s">
  <br/>
  <div>
    <div class="container">
        <div class="media-container-row">
                <h3 class="mbr-section-subtitle align-center mbr-light mbr-fonts-style display-5">
                    Chapter 19</h3>
        </div>
        <br/>
    </div>
  </div>

    <div class="container">
        <div class="media-container-row">
            <div class="row col-12 col-md-8">
              <div class="mbr-section-text">
                <p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> I’m finally done building the main model architecture. I’ve isolated it and its various helper functions into a single file and class so as to keep the structure modular and easy to use. Here’s the <a href = "assets/agent.py" style= "color:blue">file</a>, just to explain some of it in greater detail, I use the tf.concat function to concatenate the outputs of the different networks, the conv2d function creates a convolutional neural network based on the method parameters and the fc_net function does the same for fully connected layers.  <br/> </p>
                  <p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> The reason I’ve opted with this structure rather than just creates the nets in the agent class is so I don’t have to re-write the code to create the multiple different fully connected networks I intend to create (projects generally just use one network so there’s no need to create a function for this). The lrelu function implements the leaky relu activation function required for introducing some non-linearities. The code is commented profusely so you should be able to understand the rest by going through it. </p>
             </div>
            </div>
        </div>
    </div>
</section>

<section class="mbr-section content4 cid-qY4gZECclL" id="content4-l">
<div>
  <div class="container">
      <div class="media-container-row">
              <h3 class="mbr-section-subtitle align-center mbr-light mbr-fonts-style display-5">
                  Chapter 20</h3>
      </div>
      <br/>
  </div>
</div>

  <div class="container">
      <div class="media-container-row">
          <div class="row col-12 col-md-8">
            <div class="mbr-section-text">
              <p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> I’ve started work on the interactive multiplayer and it seems to be working okay. The central idea is to make it work with on just one computer on the PC’s localhost. This will remove all the hassle of LAN and having to install all the libraries and moving files from one computer to another, having to connect the computers etc.  </p>
                <br/><p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> To achieve this, we need to host a game on the local host and allow the user to control the player on the host using one script, then open another terminal and run a different script that connects to the localhost but runs the agent’s main function to choose actions.  </p><br/>
                <p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> I achieved the above set up quite easily using VizDoom’s host argument in game arguments while creating the VizDoom instance. I’m also planning on exploring multiprocessing for this task so I don’t have to start up two terminals and run two scripts every time I want to test the multiple player. I could also automate it with a batch file. I’ll upload both of those once I’m done.  </p><br/>


            </div>
          </div>
      </div>
  </div>


</section>


<section class="mbr-section article content3 cid-qYUMDBb4R7" id="content3-s">
  <br/>
  <div>
    <div class="container">
        <div class="media-container-row">
                <h3 class="mbr-section-subtitle align-center mbr-light mbr-fonts-style display-5">
                    Chapter 21 & 22</h3>
        </div>
        <br/>
    </div>
  </div>

    <div class="container">
        <div class="media-container-row">
            <div class="row col-12 col-md-8">
              <div class="mbr-section-text">
                <p class="mbr-text align-left mb-0 mbr-fonts-style display-7">  This was a very busy couple for weeks for me personally, so I wasn’t able to get a lot done. I began the long training process which took two nights. Finally, I had the weights ready in a neat 220-megabyte file (sarcasm).  <br/> </p>
                  <p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> I tested it out a lot on different scenarios using the two-script setup I developed last week and it seemed to work really well. Much better than expected actually. It averaged about four kills a game against me while I managed nine. Not bad, considering I’ve been playing this game for quite some time now. It also seemed quite robust in the sense that it wasn’t repeatedly doing the same things and (thankfully) wasn’t mindlessly running into walls. Below is a video of it playing against me. I’m going to retrain it with some different parameters because I think this can be even better.
                <video width="720" height="480" controls>
                                <source src="assets/againstRohit.mp4" type="video/mp4">
                                  Your browser does not support the video tag.
                </video>
              </p>
              <br/>
             </div>
            </div>
        </div>
    </div>
</section>



<section class="mbr-section content4 cid-qY4gZECclL" id="content4-l">
<div>
  <div class="container">
      <div class="media-container-row">
              <h3 class="mbr-section-subtitle align-center mbr-light mbr-fonts-style display-5">
                  Chapter 23</h3>
      </div>
      <br/>
  </div>
</div>

  <div class="container">
      <div class="media-container-row">
          <div class="row col-12 col-md-8">
            <div class="mbr-section-text">
              <p class="mbr-text align-left mb-0 mbr-fonts-style display-7">This week brought with it a successful implementation of the multiplayer with multiprocessing! I wrote a script that leverages the Process library in python to spawn one process and run the main method of agent instructing it to join a game hosted on the localhost (127.0.0.1) and the main process hosts and runs a spectator instance of the game allowing the user to play. The bot and player will thus be spawned into the same map and attempt to kill each other in a classic deathmatch scenario. </p> <br/>
              <p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> Taking it one step further, <a href = "assets/main.py" style= "color:blue"> heres a script </a> that spawns as many versions as the agent as specified in a command line argument and allows the host to play against them all at once. Be careful not to burn out your CPU though, each instance of the agent you add is an extra process.  </p> <br/>
            </div>
          </div>
      </div>
  </div>


</section>


<section class="mbr-section article content3 cid-qYUMDBb4R7" id="content3-s">
  <br/>
  <div>
    <div class="container">
        <div class="media-container-row">
                <h3 class="mbr-section-subtitle align-center mbr-light mbr-fonts-style display-5">
                    Chapter 24</h3>
        </div>
        <br/>
    </div>
  </div>

    <div class="container">
        <div class="media-container-row">
            <div class="row col-12 col-md-8">
              <div class="mbr-section-text">
                <p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> Very busy week with every course’s final project due but I managed to link the model to the CS1.6 convolutional network and test it against the easy bots on aim_headshot. Unfortunately, the multiplayer for CS1.6 is not going to be as straightforward due to the lack of a platform meant for learning.   <br/> </p>
                  <p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> Since we’re simply grabbing the screen buffer images and processing the video stream from there, we obviously can’t run a bot on the same computer as the host (because the bot has to see the view of the character it controls and the player has to be able to see his character’s view). Thus, I have to make this work over LAN or the Internet but I don’t think I have enough time to do this right away so I’m going to have to leave this for later.</p>
             </div>
            </div>
        </div>
    </div>
</section>

<section class="mbr-section content4 cid-qY4gZECclL" id="content4-l">
<div>
  <div class="container">
      <div class="media-container-row">
              <h3 class="mbr-section-subtitle align-center mbr-light mbr-fonts-style display-5">
                  Chapter 25 & 26</h3>
      </div>
      <br/>
  </div>
</div>

  <div class="container">
      <div class="media-container-row">
          <div class="row col-12 col-md-8">
            <div class="mbr-section-text">
              <p class="mbr-text align-left mb-0 mbr-fonts-style display-7"> I spend most of my time refactoring and documenting my code this week. I also began on writing the report and preparing for the presentation. I had to do three separate presentations, the final internal presentation to just my advisors, a fast track presentation to encourage students to attend my presentation and a public final presentation. I also had to make a video for the fast track video, I’m not the best when it comes to making videos but here’s what I managed. Below is the final fast track video.
                  <video width="720" height="480" controls>
                  <source src="assets/group27.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                  </video>
                  <br/>
            </div>
          </div>
      </div>
  </div>


</section>





<section once="" class="cid-qY3EjczH8X" id="footer7-j">





    <div class="container">
        <div class="media-container-row align-center mbr-white">
            <div class="row row-links">
                <ul class="foot-menu">





                <li class="foot-menu-item mbr-fonts-style display-7"><a href="assets/images/Resume%20-%20Rohit%20Shyla%20Kumar.pdf"><strong>Download Resume</strong></a></li><li class="foot-menu-item mbr-fonts-style display-7"><a href="mailto:rohitshylakumar@gmail.com"><strong>Contact Me</strong></a></li></ul>
            </div>
            <div class="row social-row">
                <div class="social-list align-right pb-2">






                <div class="soc-item">
                        <a href="https://github.com/Rohit-Shyla-Kumar" target="_blank">
                            <span class="mbr-iconfont mbr-iconfont-social socicon-github socicon"></span>
                        </a>
                    </div><div class="soc-item">
                        <a href="https://www.facebook.com/rohit.shylakumar" target="_blank">
                            <span class="mbr-iconfont mbr-iconfont-social socicon-facebook socicon"></span>
                        </a>
                    </div><div class="soc-item">
                        <a href="https://www.linkedin.com/in/rohit-shyla-kumar-765460139/" target="_blank">
                            <span class="mbr-iconfont mbr-iconfont-social socicon-linkedin socicon"></span>
                        </a>
                    </div></div>
            </div>
            <div class="row row-copirayt">
                <p class="mbr-text mb-0 mbr-fonts-style mbr-white align-center display-7">
                    © Copyright 2018 Rohit Shyla Kumar - All Rights Reserved
                </p>
            </div>
        </div>
    </div>
</section>


  <script src="assets/web/assets/jquery/jquery.min.js"></script>
  <script src="assets/popper/popper.min.js"></script>
  <script src="assets/tether/tether.min.js"></script>
  <script src="assets/bootstrap/js/bootstrap.min.js"></script>
  <script src="assets/smoothscroll/smooth-scroll.js"></script>
  <script src="assets/touchswipe/jquery.touch-swipe.min.js"></script>
  <script src="assets/viewportchecker/jquery.viewportchecker.js"></script>
  <script src="assets/dropdown/js/script.min.js"></script>
  <script src="assets/theme/js/script.js"></script>


  <input name="animation" type="hidden">
  </body>
</html>
